{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dgl\n",
    "import torch\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import jaccard_score\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import dgl\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from stepmix import StepMix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_ratings = pd.read_csv('D:\\\\CODE\\\\multi-model knowledge graph multi-graph recommendation system\\\\data\\\\cleanuser_rating.csv')\n",
    "crew_info_df = pd.read_csv('D:\\\\CODE\\\\multi-model knowledge graph multi-graph recommendation system\\\\data\\\\final_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roles_and_initialize_graph(crew_info_df):\n",
    "    \"\"\"从crew_info数据中提取所有唯一的角色类型，并为每个角色创建唯一的ID映射。\"\"\"\n",
    "    roles = {}  # 使用字典来存储每个角色的ID映射\n",
    "    edge_types = []\n",
    "    for _, row in crew_info_df.iterrows():\n",
    "        crew_info = parse_crew_info(row['crew_info'])\n",
    "        for role, ids in crew_info.items():\n",
    "            if role not in roles:\n",
    "                roles[role] = {}\n",
    "            for person_id in ids:\n",
    "                if person_id not in roles[role]:\n",
    "                    roles[role][person_id] = len(roles[role])\n",
    "            edge_types.append(('movie', f'has_{role}', role))\n",
    "    return roles, edge_types\n",
    "\n",
    "def parse_crew_info(crew_info_str):\n",
    "    \"\"\"解析制作团队信息字符串，返回字典格式：{角色: [id, ...]}\"\"\"\n",
    "    # 使用正则表达式匹配所有的角色和ID组合\n",
    "    pattern = re.compile(r\"(\\w+): ([\\w, ]+)\")\n",
    "    matches = pattern.findall(crew_info_str)\n",
    "    crew_info = {}\n",
    "    for role, ids in matches:\n",
    "        # 将ID字符串分割并去除空格，然后转换为列表\n",
    "        crew_info[role] = ids.replace(' ', '').split(',')\n",
    "    return crew_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下為目前知識圖的建構完整版\n",
    "# 第一版 下面的是第二版加入了movieId\n",
    "再來只需要把提取出的特徵放入就完成了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stepmix import StepMix\n",
    "\n",
    "import numpy as np\n",
    "user_movie_matrix = pd.pivot_table(df_ratings, index='userId', columns='movieId', aggfunc='size', fill_value=0)\n",
    "\n",
    "# 將 pivot table 轉換為 0 或 1，表示是否觀看\n",
    "user_movie_matrix = (user_movie_matrix > 0).astype(int)\n",
    "\n",
    "# 轉換成適用於 StepMix 的數據格式\n",
    "data = user_movie_matrix.values\n",
    "def hellinger_distance(p, q):\n",
    "    return np.sqrt(np.sum((np.sqrt(p) - np.sqrt(q)) ** 2)) / np.sqrt(2)\n",
    "\n",
    "def compute_user_similarity(membership_probabilities, user_ids, threshold):\n",
    "    num_users = len(user_ids)\n",
    "    user_similarity_edges = []\n",
    "    for i in range(num_users):\n",
    "        for j in range(i + 1, num_users):\n",
    "            dist = hellinger_distance(membership_probabilities[i], membership_probabilities[j])\n",
    "            if dist <= threshold:\n",
    "                user_similarity_edges.append((i, j))\n",
    "    return user_similarity_edges\n",
    "\n",
    "\n",
    "def create_heterogeneous_graph(df_ratings, crew_info_df, Uthreshold=0.5, threshold=0.7):\n",
    "    user_ids = df_ratings['userId'].unique()\n",
    "    \n",
    "    movie_ids = df_ratings['movieId'].unique()\n",
    "    user_id_map = {uid: i for i, uid in enumerate(user_ids)}\n",
    "    movie_id_map = {mid: i for i, mid in enumerate(movie_ids)}\n",
    "    \n",
    "    \n",
    "    roles, edge_types = extract_roles_and_initialize_graph(crew_info_df)\n",
    "    \n",
    "    edge_types.extend([\n",
    "        ('movie', 'has_image', 'movieimage'),\n",
    "        ('movie', 'has_text', 'movietext'),\n",
    "        ('movie', 'has_audio', 'movieaudio'),\n",
    "        ('user', 'rates', 'movie'),  \n",
    "        ('user', 'similar', 'user'), \n",
    "        ('movie', 'similar', 'movie') \n",
    "    ])\n",
    "    g = dgl.heterograph({etype: [] for etype in edge_types},\n",
    "                        num_nodes_dict={\n",
    "                            'user': len(user_ids), \n",
    "                            'movie': len(movie_ids),\n",
    "                            **{role: len(ids) for role, ids in roles.items()},\n",
    "                            'movieimage': len(movie_ids),  \n",
    "                            'movietext': len(movie_ids),\n",
    "                            'movieaudio': len(movie_ids)\n",
    "                        })\n",
    "    for idx, row in tqdm(crew_info_df.iterrows(), total=crew_info_df.shape[0], desc=\"Processing crew info\"):\n",
    "        movie_id = row['movieId']\n",
    "        if movie_id in movie_id_map:\n",
    "            crew_info = parse_crew_info(row['crew_info'])\n",
    "            for role, ids in crew_info.items():\n",
    "                src = []\n",
    "                dst = []\n",
    "                for person_id in ids:\n",
    "                    src.append(movie_id_map[movie_id])\n",
    "                    dst.append(roles[role][person_id])\n",
    "                g.add_edges(src, dst, etype=('movie', f'has_{role}', role))\n",
    "\n",
    "\n",
    "    user_movie_matrix = df_ratings.pivot_table(index='userId', columns='movieId', aggfunc='size', fill_value=0)\n",
    "    \n",
    "    model = StepMix(n_components=3, measurement='categorical')\n",
    "    model.fit(data)\n",
    "    membership_probabilities = model.predict_proba(data)\n",
    "    user_similarity = compute_user_similarity(membership_probabilities, user_ids, Uthreshold)\n",
    "    movie_similarity = [(movie_id_map[m1], movie_id_map[m2]) for m1, m2 in combinations(movie_ids, 2)\n",
    "                        if jaccard_score(user_movie_matrix[m1].fillna(0), user_movie_matrix[m2].fillna(0)) >= threshold]\n",
    "    \n",
    "    if user_similarity:\n",
    "        src, dst = zip(*user_similarity)\n",
    "        g.add_edges(src, dst, etype=('user', 'similar', 'user'))\n",
    "    if movie_similarity:\n",
    "        src, dst = zip(*movie_similarity)\n",
    "        g.add_edges(src, dst, etype=('movie', 'similar', 'movie'))\n",
    "\n",
    "    user_movie_interactions = [(user_id_map[row['userId']], movie_id_map[row['movieId']])\n",
    "                               for index, row in df_ratings.iterrows()]\n",
    "    if user_movie_interactions:\n",
    "        src, dst = zip(*user_movie_interactions)\n",
    "        g.add_edges(src, dst, etype=('user', 'rates', 'movie'))\n",
    "    g.nodes['movie'].data['movie_id'] = torch.tensor([int(mid) for mid in movie_ids], dtype=torch.int64)\n",
    "\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前特徵提取的創建圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing crew info: 100%|██████████| 6011/6011 [00:19<00:00, 314.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting StepMix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializations (n_init) : 100%|██████████| 1/1 [24:52<00:00, 1492.22s/it, max_LL=-1.81e+6, max_avg_LL=-149]\n"
     ]
    }
   ],
   "source": [
    "hetero_graph = create_heterogeneous_graph(df_ratings, crew_info_df)\n",
    "with open('new_hetero_graph05.pkl', 'wb') as f:\n",
    "    pickle.dump(hetero_graph, f)\n",
    "    \n",
    "print(hetero_graph)\n",
    "print(hetero_graph.ntypes, hetero_graph.etypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "節點和邊的數量:\n",
    "actor節點數量: 4566\n",
    "actress節點數量: 3701\n",
    "composer節點數量: 2011\n",
    "director節點數量: 4010\n",
    "editor節點數量: 2489\n",
    "movie節點數量: 5996\n",
    "movieaudio節點數量: 5996\n",
    "movieimage節點數量: 5996\n",
    "movietext節點數量: 5996\n",
    "producer節點數量: 3952\n",
    "self節點數量: 1049\n",
    "user節點數量: 12171\n",
    "writer節點數量: 3177\n",
    "('movie', 'has_actor', 'actor')邊數量: 9809\n",
    "('movie', 'has_actress', 'actress')邊數量: 8327\n",
    "('movie', 'has_audio', 'movieaudio')邊數量: 0\n",
    "('movie', 'has_composer', 'composer')邊數量: 5923\n",
    "('movie', 'has_director', 'director')邊數量: 10163\n",
    "('movie', 'has_editor', 'editor')邊數量: 4089\n",
    "('movie', 'has_image', 'movieimage')邊數量: 0\n",
    "('movie', 'has_producer', 'producer')邊數量: 9891\n",
    "('movie', 'has_self', 'self')邊數量: 2138\n",
    "('movie', 'has_text', 'movietext')邊數量: 0\n",
    "('movie', 'has_writer', 'writer')邊數量: 7036\n",
    "('movie', 'similar', 'movie')邊數量: 4852\n",
    "('user', 'rates', 'movie')邊數量: 549919\n",
    "('user', 'similar', 'user')邊數量: 28889524\n",
    "\n",
    "('movie', 'has_actor', 'actor')\n",
    "('movie', 'has_actress', 'actress')\n",
    "('movie', 'has_audio', 'movieaudio')\n",
    "('movie', 'has_composer', 'composer')\n",
    "('movie', 'has_director', 'director')\n",
    "('movie', 'has_editor', 'editor')\n",
    "('movie', 'has_image', 'movieimage')\n",
    "('movie', 'has_producer', 'producer')\n",
    "('movie', 'has_self', 'self')\n",
    "('movie', 'has_text', 'movietext')\n",
    "('movie', 'has_writer', 'writer')\n",
    "('movie', 'similar', 'movie')\n",
    "('user', 'rates', 'movie')\n",
    "('user', 'similar', 'user')\n",
    "\n",
    "檢查預期的邊類型:\n",
    "邊 ('user', 'rates', 'movie') 存在.\n",
    "邊 ('movie', 'similar', 'movie') 存在.\n",
    "邊 ('user', 'similar', 'user') 存在.\n",
    "邊 ('movie', 'has_image', 'movieimage') 存在.\n",
    "邊 ('movie', 'has_text', 'movietext') 存在.\n",
    "邊 ('movie', 'has_audio', 'movieaudio') 存在."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元圖結構:\n",
      "[('movie', 'actor'), ('movie', 'actress'), ('movie', 'movieaudio'), ('movie', 'composer'), ('movie', 'director'), ('movie', 'editor'), ('movie', 'movieimage'), ('movie', 'producer'), ('movie', 'self'), ('movie', 'movietext'), ('movie', 'writer'), ('movie', 'movie'), ('user', 'movie'), ('user', 'user')]\n",
      "\n",
      "節點和邊的數量:\n",
      "actor節點數量: 4566\n",
      "actress節點數量: 3701\n",
      "composer節點數量: 2011\n",
      "director節點數量: 4010\n",
      "editor節點數量: 2489\n",
      "movie節點數量: 5996\n",
      "movieaudio節點數量: 5996\n",
      "movieimage節點數量: 5996\n",
      "movietext節點數量: 5996\n",
      "producer節點數量: 3952\n",
      "self節點數量: 1049\n",
      "user節點數量: 12171\n",
      "writer節點數量: 3177\n",
      "('movie', 'has_actor', 'actor')邊數量: 9809\n",
      "('movie', 'has_actress', 'actress')邊數量: 8327\n",
      "('movie', 'has_audio', 'movieaudio')邊數量: 0\n",
      "('movie', 'has_composer', 'composer')邊數量: 5923\n",
      "('movie', 'has_director', 'director')邊數量: 10163\n",
      "('movie', 'has_editor', 'editor')邊數量: 4089\n",
      "('movie', 'has_image', 'movieimage')邊數量: 0\n",
      "('movie', 'has_producer', 'producer')邊數量: 9891\n",
      "('movie', 'has_self', 'self')邊數量: 2138\n",
      "('movie', 'has_text', 'movietext')邊數量: 0\n",
      "('movie', 'has_writer', 'writer')邊數量: 7036\n",
      "('movie', 'similar', 'movie')邊數量: 4852\n",
      "('user', 'rates', 'movie')邊數量: 549919\n",
      "('user', 'similar', 'user')邊數量: 28889524\n",
      "\n",
      "檢查預期的邊類型:\n",
      "邊 ('user', 'rates', 'movie') 存在.\n",
      "邊 ('movie', 'similar', 'movie') 存在.\n",
      "邊 ('user', 'similar', 'user') 存在.\n",
      "邊 ('movie', 'has_image', 'movieimage') 存在.\n",
      "邊 ('movie', 'has_text', 'movietext') 存在.\n",
      "邊 ('movie', 'has_audio', 'movieaudio') 存在.\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import pickle\n",
    "\n",
    "with open('hetero_graph02.pkl', 'rb') as f:\n",
    "    hetero_graph = pickle.load(f)\n",
    "\n",
    "# 列印元圖，顯示所有的節點類型和邊類型\n",
    "print(\"元圖結構:\")\n",
    "print(hetero_graph.metagraph().edges())\n",
    "\n",
    "print(\"\\n節點和邊的數量:\")\n",
    "for ntype in hetero_graph.ntypes:\n",
    "    print(f\"{ntype}節點數量: {hetero_graph.number_of_nodes(ntype)}\")\n",
    "for etype in hetero_graph.canonical_etypes:\n",
    "    print(f\"{etype}邊數量: {hetero_graph.number_of_edges(etype)}\")\n",
    "\n",
    "# 检檢查特定的邊類型是否存在\n",
    "expected_edges = [\n",
    "    ('user', 'rates', 'movie'),\n",
    "    ('movie', 'similar', 'movie'),\n",
    "    ('user', 'similar', 'user'),\n",
    "    ('movie', 'has_image', 'movieimage'),\n",
    "    ('movie', 'has_text', 'movietext'),\n",
    "    ('movie', 'has_audio', 'movieaudio')\n",
    "]\n",
    "\n",
    "print(\"\\n檢查預期的邊類型:\")\n",
    "for edge in expected_edges:\n",
    "    if edge in hetero_graph.canonical_etypes:\n",
    "        print(f\"邊 {edge} 存在.\")\n",
    "    else:\n",
    "        print(f\"邊 {edge} 不存在.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 之後要跑特徵提取使用特徵提取資料夾裡面的PY檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from moviepy.editor import VideoFileClip\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet特徵提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie IDs are available in the graph.\n",
      "Sample Movie IDs: tensor([54995, 57368, 60161, 62956, 64614])\n"
     ]
    }
   ],
   "source": [
    "# 加载图\n",
    "with open('hetero_graph.pkl', 'rb') as f:\n",
    "    hetero_graph = pickle.load(f)\n",
    "\n",
    "# 检查 'movie' 节点是否有 'movie_id' 属性\n",
    "if 'movie_id' in hetero_graph.nodes['movie'].data:\n",
    "    print(\"Movie IDs are available in the graph.\")\n",
    "    print(\"Sample Movie IDs:\", hetero_graph.nodes['movie'].data['movie_id'][:5])\n",
    "else:\n",
    "    print(\"Movie IDs are not set in the graph.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing IvNkGm8mxiM.mp4: 100%|██████████| 20/20 [00:00<00:00, 104.99it/s]\n",
      "Processing xGwC7U6Sf3o.mp4: 100%|██████████| 20/20 [00:00<00:00, 203.67it/s]\n",
      "Processing 0aHJmM2uvBY.mp4: 100%|██████████| 20/20 [00:00<00:00, 269.47it/s]\n",
      "Processing vLkBUix_D3U.mp4: 100%|██████████| 20/20 [00:01<00:00, 18.90it/s]\n",
      "Processing unSbtED22Fw.mp4: 100%|██████████| 20/20 [00:00<00:00, 168.80it/s]\n",
      "Processing YkHmYJmfuWg.mp4: 100%|██████████| 20/20 [00:00<00:00, 105.78it/s]\n",
      "Processing -NeQ6aGWX74.mp4: 100%|██████████| 20/20 [00:00<00:00, 25.81it/s]\n",
      "Processing 4aamMJ_8qZ4.mp4: 100%|██████████| 20/20 [00:00<00:00, 47.53it/s]\n",
      "Processing tDe3kbmTlCE.mp4: 100%|██████████| 20/20 [00:00<00:00, 60.97it/s]\n",
      "Processing AIzbwV7on6Q.mp4: 100%|██████████| 20/20 [00:01<00:00, 15.30it/s]\n",
      "Processing t2koYVqwzT4.mp4: 100%|██████████| 20/20 [00:00<00:00, 37.93it/s]\n",
      "Processing YOOIK0baLvM.mp4: 100%|██████████| 20/20 [00:03<00:00,  5.02it/s]\n",
      "Processing jj6wcUes1no.mp4: 100%|██████████| 20/20 [00:01<00:00, 18.09it/s]\n",
      "Processing 2huFZpVeZX0.mp4: 100%|██████████| 20/20 [00:03<00:00,  5.39it/s]\n",
      "Processing 8m9EVP8X7N8.mp4: 100%|██████████| 20/20 [00:03<00:00,  5.26it/s]\n",
      "Processing O5w8PurIFkk.mp4: 100%|██████████| 20/20 [00:04<00:00,  4.52it/s]\n",
      "Processing 0RqDiYnFxTk.mp4: 100%|██████████| 20/20 [00:01<00:00, 14.38it/s]\n",
      "Processing eZ4xDTz8Avc.mp4: 100%|██████████| 20/20 [00:01<00:00, 13.34it/s]\n",
      "Processing epHKc6O7LqQ.mp4: 100%|██████████| 20/20 [00:03<00:00,  6.56it/s]\n",
      "Processing bpXfcTF6iVk.mp4: 100%|██████████| 20/20 [00:01<00:00, 14.59it/s]\n",
      "Processing Cook_OOKWlw.mp4: 100%|██████████| 20/20 [00:01<00:00, 12.94it/s]\n",
      "Processing l9DFAyYaNtI.mp4: 100%|██████████| 20/20 [00:00<00:00, 70.84it/s]\n",
      "Processing 3PR2lDTpRak.mp4: 100%|██████████| 20/20 [00:03<00:00,  6.12it/s]\n",
      "Processing ne6p6MfLBxc.mp4: 100%|██████████| 20/20 [00:03<00:00,  5.57it/s]\n",
      "Processing xzitmvuOLKE.mp4: 100%|██████████| 20/20 [00:00<00:00, 275.80it/s]\n",
      "Processing XbXdwBNkCmk.mp4: 100%|██████████| 20/20 [00:01<00:00, 15.38it/s]\n",
      "Processing ICp4g9p_rgo.mp4: 100%|██████████| 20/20 [00:00<00:00, 75.40it/s]\n",
      "Processing RBw_jE2EKvQ.mp4: 100%|██████████| 20/20 [00:02<00:00,  7.36it/s]\n",
      "Processing AIzbwV7on6Q.mp4: 100%|██████████| 20/20 [00:00<00:00, 21.17it/s]\n",
      "Processing vLkBUix_D3U.mp4: 100%|██████████| 20/20 [00:00<00:00, 21.62it/s]\n",
      "Processing W3_3FKPRoLM.mp4: 100%|██████████| 20/20 [00:00<00:00, 78.24it/s]\n",
      "Processing gMhMQuOIWiQ.mp4: 100%|██████████| 20/20 [00:00<00:00, 64.16it/s]\n",
      "Processing NUB7Lhx_0ao.mp4: 100%|██████████| 20/20 [00:04<00:00,  4.89it/s]\n",
      "Processing RBw_jE2EKvQ.mp4: 100%|██████████| 20/20 [00:02<00:00,  8.22it/s]\n",
      "Processing vLkBUix_D3U.mp4: 100%|██████████| 20/20 [00:01<00:00, 19.42it/s]\n",
      "Processing p_TDzemiYu4.mp4: 100%|██████████| 20/20 [00:01<00:00, 19.38it/s]\n",
      "Processing mXI3obHfwgU.mp4: 100%|██████████| 20/20 [00:00<00:00, 31.94it/s]\n",
      "Processing Y6K0h8E6bCI.mp4: 100%|██████████| 20/20 [00:03<00:00,  5.83it/s]\n",
      "Processing twuScTcDP_Q.mp4: 100%|██████████| 20/20 [00:00<00:00, 20.94it/s]\n",
      "Processing YOOIK0baLvM.mp4: 100%|██████████| 20/20 [00:03<00:00,  6.25it/s]\n",
      "Processing jj6wcUes1no.mp4: 100%|██████████| 20/20 [00:01<00:00, 19.95it/s]\n",
      "Processing 2huFZpVeZX0.mp4: 100%|██████████| 20/20 [00:03<00:00,  5.46it/s]\n",
      "Processing twuScTcDP_Q.mp4: 100%|██████████| 20/20 [00:00<00:00, 20.13it/s]\n",
      "Processing YOOIK0baLvM.mp4: 100%|██████████| 20/20 [00:03<00:00,  5.89it/s]\n",
      "Processing vVGbPFdU96A.mp4: 100%|██████████| 20/20 [00:01<00:00, 14.61it/s]\n",
      "Processing 2RB3edZyeYw.mp4: 100%|██████████| 20/20 [00:01<00:00, 15.36it/s]\n",
      "Processing OlhLOWTnVoQ.mp4: 100%|██████████| 20/20 [00:03<00:00,  5.42it/s]\n",
      "Processing P0ppBlL2lC4.mp4: 100%|██████████| 20/20 [00:01<00:00, 14.06it/s]\n",
      "Processing k-OOfW6wWyQ.mp4: 100%|██████████| 20/20 [00:01<00:00, 13.93it/s]\n",
      "Processing z5Humz3ONgk.mp4: 100%|██████████| 20/20 [00:02<00:00,  7.68it/s]\n",
      "Processing IvNkGm8mxiM.mp4: 100%|██████████| 20/20 [00:00<00:00, 86.37it/s]\n",
      "Processing _wkqo_Rd3_Q.mp4: 100%|██████████| 20/20 [00:02<00:00,  7.38it/s]\n",
      "Processing rvpsiIe2vBE.mp4: 100%|██████████| 20/20 [00:01<00:00, 10.54it/s]\n",
      "Processing gMhMQuOIWiQ.mp4: 100%|██████████| 20/20 [00:00<00:00, 60.69it/s]\n",
      "Processing Hp_ZwQH2nfI.mp4: 100%|██████████| 20/20 [00:00<00:00, 20.10it/s]\n",
      "Processing Y6K0h8E6bCI.mp4: 100%|██████████| 20/20 [00:02<00:00,  6.79it/s]\n",
      "Processing 4F--nHysJkw.mp4: 100%|██████████| 20/20 [00:01<00:00, 13.22it/s]\n",
      "Processing bL2wDI-O5YQ.mp4: 100%|██████████| 20/20 [00:00<00:00, 210.41it/s]\n",
      "Processing ZaaLsOyUm_Q.mp4: 100%|██████████| 20/20 [00:03<00:00,  5.52it/s]\n",
      "Processing QFpOSZIegeg.mp4: 100%|██████████| 20/20 [00:00<00:00, 162.61it/s]\n",
      "Processing AIzbwV7on6Q.mp4: 100%|██████████| 20/20 [00:00<00:00, 20.87it/s]\n",
      "Processing 2xOUCZH14Is.mp4: 100%|██████████| 20/20 [00:00<00:00, 79.20it/s]\n",
      "Processing p_TDzemiYu4.mp4: 100%|██████████| 20/20 [00:00<00:00, 20.57it/s]\n",
      "Processing mXI3obHfwgU.mp4: 100%|██████████| 20/20 [00:00<00:00, 34.60it/s]\n",
      "Processing Y6K0h8E6bCI.mp4: 100%|██████████| 20/20 [00:02<00:00,  6.79it/s]\n",
      "Processing XbXdwBNkCmk.mp4: 100%|██████████| 20/20 [00:01<00:00, 15.42it/s]\n",
      "Processing AIzbwV7on6Q.mp4: 100%|██████████| 20/20 [00:00<00:00, 21.16it/s]\n",
      "Processing vLkBUix_D3U.mp4: 100%|██████████| 20/20 [00:00<00:00, 21.13it/s]\n",
      "Processing dZXatzQ1kzg.mp4: 100%|██████████| 20/20 [00:00<00:00, 50.20it/s]\n",
      "Processing 4F--nHysJkw.mp4: 100%|██████████| 20/20 [00:01<00:00, 14.37it/s]\n",
      "Processing twuScTcDP_Q.mp4: 100%|██████████| 20/20 [00:00<00:00, 21.09it/s]\n",
      "Processing YOOIK0baLvM.mp4: 100%|██████████| 20/20 [00:03<00:00,  6.59it/s]\n",
      "Processing jj6wcUes1no.mp4: 100%|██████████| 20/20 [00:00<00:00, 20.96it/s]\n",
      "Processing _wkqo_Rd3_Q.mp4: 100%|██████████| 20/20 [00:02<00:00,  9.23it/s]\n",
      "Processing YOOIK0baLvM.mp4: 100%|██████████| 20/20 [00:02<00:00,  6.72it/s]\n",
      "Processing 8m9EVP8X7N8.mp4: 100%|██████████| 20/20 [00:03<00:00,  6.53it/s]\n",
      "Processing OlhLOWTnVoQ.mp4: 100%|██████████| 20/20 [00:02<00:00,  6.68it/s]\n",
      "Processing EbCoDf44oCE.mp4: 100%|██████████| 20/20 [00:03<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征已成功添加到图中。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "from PIL import Image\n",
    "from moviepy.editor import VideoFileClip\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import dgl\n",
    "\n",
    "def load_youtube_to_movie_mapping(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    # 從 movieId 到 youtubeId 建立字典\n",
    "    movie_to_youtube = pd.Series(df.youtubeId.values, index=df.movieId.astype(str)).to_dict()\n",
    "    return movie_to_youtube\n",
    "\n",
    "# def load_pretrained_resnet50():\n",
    "#     resnet50 = models.resnet50(pretrained=True)\n",
    "#     resnet50.eval()\n",
    "#     resnet50 = resnet50.to('cuda')\n",
    "#     return resnet50\n",
    "def load_pretrained_resnet50():\n",
    "    resnet50 = models.resnet50(pretrained=True)\n",
    "    # 修改模型以仅使用到池化层的输出\n",
    "    resnet50 = torch.nn.Sequential(*list(resnet50.children())[:-1])\n",
    "    resnet50.eval()\n",
    "    resnet50 = resnet50.to('cuda')\n",
    "    return resnet50\n",
    "\n",
    "def preprocess_frames(frames, size=(224, 224)):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.CenterCrop(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    batch_tensor = torch.stack([preprocess(Image.fromarray(frame)) for frame in frames])\n",
    "    return batch_tensor.to('cuda')\n",
    "\n",
    "# def extract_features_from_video(video_path, model, preprocess, start_sec=10, end_sec=30, fps=1, batch_size=32):\n",
    "#     try:\n",
    "#         clip = VideoFileClip(video_path).subclip(start_sec, end_sec)\n",
    "#         total_frames = int((end_sec - start_sec) * fps)\n",
    "#         frame_features = []\n",
    "#         batch = []\n",
    "#         # 將 tqdm 添加到迭代影片幀的循環中\n",
    "#         for frame in tqdm(clip.iter_frames(fps=fps, dtype='uint8'), total=total_frames, desc=f\"Processing {os.path.basename(video_path)}\"):\n",
    "#             batch.append(frame)\n",
    "#             if len(batch) == batch_size:\n",
    "#                 img_tensor = preprocess(batch)\n",
    "#                 with torch.no_grad():\n",
    "#                     features = model(img_tensor)\n",
    "#                 frame_features.extend(features.cpu().numpy())\n",
    "#                 batch = []  # 清空批量列表以進行下一批次的處理\n",
    "\n",
    "#         # 處理剩餘的幀（如果有）\n",
    "#         if batch:\n",
    "#             img_tensor = preprocess(batch)\n",
    "#             with torch.no_grad():\n",
    "#                 features = model(img_tensor)\n",
    "#             frame_features.extend(features.cpu().numpy())\n",
    "\n",
    "#         clip.close()\n",
    "#         return np.mean(frame_features, axis=0)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing video {video_path}: {str(e)}\")\n",
    "#         return None\n",
    "\n",
    "def extract_features_from_video(video_path, model, preprocess, start_sec=10, end_sec=30, fps=1, batch_size=32):# start_sec=10, end_sec=30是預告片的秒數之後要改回3-180\n",
    "    try:\n",
    "        clip = VideoFileClip(video_path).subclip(start_sec, end_sec)\n",
    "        total_frames = int((end_sec - start_sec) * fps)\n",
    "        frame_features = []\n",
    "        batch = []\n",
    "        for frame in tqdm(clip.iter_frames(fps=fps, dtype='uint8'), total=total_frames, desc=f\"Processing {os.path.basename(video_path)}\"):\n",
    "            batch.append(frame)\n",
    "            if len(batch) == batch_size:\n",
    "                img_tensor = preprocess(batch)\n",
    "                with torch.no_grad():\n",
    "                    features = model(img_tensor)\n",
    "                    # 确保特征被展平到正确的维度\n",
    "                    features = features.view(features.size(0), -1)\n",
    "                frame_features.extend(features.cpu().numpy())\n",
    "                batch = []  # Reset batch\n",
    "\n",
    "        # 处理剩余的帧（如果有）\n",
    "        if batch:\n",
    "            img_tensor = preprocess(batch)\n",
    "            with torch.no_grad():\n",
    "                features = model(img_tensor)\n",
    "                # 确保特征被展平到正确的维度\n",
    "                features = features.view(features.size(0), -1)\n",
    "            frame_features.extend(features.cpu().numpy())\n",
    "\n",
    "        clip.close()\n",
    "        return np.mean(frame_features, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video {video_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def add_features_to_graph(g, features_dict):\n",
    "    # 获取电影图像节点的数量\n",
    "    num_movies = g.number_of_nodes('movieimage')\n",
    "    \n",
    "    # 预设特征矩阵，假设我们事先知道特征的维度，例如使用ResNet50提取的特征维度是2048\n",
    "    num_features = 2048  # 或者根据第一个有效特征动态获取\n",
    "    features_tensor = torch.zeros((num_movies, num_features))\n",
    "\n",
    "    # 添加特征到图中\n",
    "    movie_indices = []\n",
    "    for movie_id, features in features_dict.items():\n",
    "        # 尝试获取对应movie_id的索引，假设movie和movieimage索引已对齐\n",
    "        try:\n",
    "            idx = g.nodes['movie'].data['movie_id'].tolist().index(int(movie_id))\n",
    "            movie_indices.append(idx)\n",
    "            if features is not None:\n",
    "                # 转换特征为torch张量\n",
    "                feature_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "                # 确保特征维度正确\n",
    "                if feature_tensor.numel() == num_features:\n",
    "                    features_tensor[idx] = feature_tensor\n",
    "                else:\n",
    "                    print(f\"特征维度不一致: {feature_tensor.numel()} 期望: {num_features}\")\n",
    "            else:\n",
    "                # 如果没有特征也更新索引，但已初始化为0\n",
    "                print(f\"无特征数据: movie_id {movie_id}\")\n",
    "        except ValueError:\n",
    "            print(f\"movie_id {movie_id} 在图中找不到对应的索引\")\n",
    "\n",
    "    # 更新图中的特征数据\n",
    "    g.nodes['movieimage'].data['features'] = features_tensor\n",
    "    print(\"特征已成功添加到图中。\")\n",
    "\n",
    "# 加载现有图\n",
    "with open('hetero_graph.pkl', 'rb') as f:\n",
    "    hetero_graph = pickle.load(f)\n",
    "\n",
    "# 执行特征提取和映射\n",
    "movie_to_youtube = load_youtube_to_movie_mapping('D:\\\\CODE\\\\multi-model knowledge graph multi-graph recommendation system\\\\data\\\\ml-youtube_cleaned.csv')\n",
    "resnet50 = load_pretrained_resnet50()\n",
    "video_folder = 'D:\\\\CODE\\\\multi-model knowledge graph multi-graph recommendation system\\\\data\\\\videos'\n",
    "features_dict = {}\n",
    "\n",
    "\n",
    "# Extract and store features for the first 10 movies per user\n",
    "user_movie_edges = hetero_graph.edges(etype=('user', 'rates', 'movie'))\n",
    "features_dict = {}\n",
    "\n",
    "# Process only the first 10 movies for each user 這邊是取每個使用者的前10部電影的預告片之後要改回所有的預告片\n",
    "for user_id in torch.unique(user_movie_edges[0]):\n",
    "    movie_ids = user_movie_edges[1][user_movie_edges[0] == user_id][:10]  # Only take first 10 movies\n",
    "    for movie_id in movie_ids:\n",
    "        movie_id = hetero_graph.nodes['movie'].data['movie_id'][movie_id].item()  # Get actual movie ID\n",
    "        youtube_id = movie_to_youtube.get(str(movie_id))\n",
    "        if youtube_id:\n",
    "            video_path = os.path.join(video_folder, f\"{youtube_id}.mp4\")\n",
    "            if os.path.exists(video_path):\n",
    "                features = extract_features_from_video(video_path, resnet50, preprocess_frames)\n",
    "                if features is not None:\n",
    "                    features_dict[str(movie_id)] = features\n",
    "\n",
    "# # 加上 tqdm 進度條追蹤提取特徵的進度\n",
    "# for movie_id, youtube_id in tqdm(movie_to_youtube.items(), desc=\"Extracting features from videos\"):\n",
    "#     video_path = os.path.join(video_folder, f\"{youtube_id}.mp4\")\n",
    "#     if os.path.exists(video_path):\n",
    "#         features = extract_features_from_video(video_path, resnet50)\n",
    "#         features_dict[movie_id] = features\n",
    "\n",
    "add_features_to_graph(hetero_graph, features_dict)\n",
    "\n",
    "# 保存更新后的图像特征图\n",
    "with open('hetero_graph_with_images.pkl', 'wb') as f:\n",
    "    pickle.dump(hetero_graph, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多圖+一秒取一幀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "from PIL import Image\n",
    "from moviepy.editor import VideoFileClip\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import dgl\n",
    "\n",
    "def load_youtube_to_movie_mapping(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    # 从 movieId 到 youtubeId 创建字典\n",
    "    movie_to_youtube = pd.Series(df.youtubeId.values, index=df.movieId.astype(str)).to_dict()\n",
    "    return movie_to_youtube\n",
    "\n",
    "def load_pretrained_resnet50():\n",
    "    resnet50 = models.resnet50(pretrained=True)\n",
    "    # 将模型修改为仅到池化层的输出\n",
    "    resnet50 = torch.nn.Sequential(*list(resnet50.children())[:-1])\n",
    "    resnet50.eval()\n",
    "    resnet50 = resnet50.to('cuda')\n",
    "    return resnet50\n",
    "\n",
    "def preprocess_frames(frames, size=(224, 224)):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.CenterCrop(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    batch_tensor = torch.stack([preprocess(Image.fromarray(frame)) for frame in frames])\n",
    "    return batch_tensor.to('cuda')\n",
    "\n",
    "def extract_features_from_video(video_path, model, preprocess, start_sec=10, end_sec=30, fps=1, batch_size=32):\n",
    "    try:\n",
    "        clip = VideoFileClip(video_path).subclip(start_sec, end_sec)\n",
    "        total_frames = int((end_sec - start_sec) * fps)\n",
    "        frame_features = []\n",
    "        batch = []\n",
    "        for frame in tqdm(clip.iter_frames(fps=fps, dtype='uint8'), total=total_frames, desc=f\"Processing {os.path.basename(video_path)}\"):\n",
    "            batch.append(frame)\n",
    "            if len(batch) == batch_size:\n",
    "                img_tensor = preprocess(batch)\n",
    "                with torch.no_grad():\n",
    "                    features = model(img_tensor)\n",
    "                    features = features.view(features.size(0), -1)  # 确保特征被展平\n",
    "                frame_features.extend(features.cpu().numpy())\n",
    "                batch = []  # Reset batch\n",
    "\n",
    "        if batch:  # 处理剩余的帧\n",
    "            img_tensor = preprocess(batch)\n",
    "            with torch.no_grad():\n",
    "                features = model(img_tensor)\n",
    "                features = features.view(features.size(0), -1)\n",
    "            frame_features.extend(features.cpu().numpy())\n",
    "\n",
    "        clip.close()\n",
    "        return np.mean(frame_features, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video {video_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def add_features_to_graph(g, features_dict):\n",
    "    num_movies = g.number_of_nodes('movieimage')\n",
    "    num_features = 2048\n",
    "    features_tensor = torch.zeros((num_movies, num_features))\n",
    "\n",
    "    for movie_id, features in features_dict.items():\n",
    "        try:\n",
    "            idx = g.nodes['movie'].data['movie_id'].tolist().index(int(movie_id))\n",
    "            if features is not None:\n",
    "                feature_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "                if feature_tensor.numel() == num_features:\n",
    "                    features_tensor[idx] = feature_tensor\n",
    "                else:\n",
    "                    print(f\"特征维度不一致: {feature_tensor.numel()} 期望: {num_features}\")\n",
    "            else:\n",
    "                print(f\"无特征数据: movie_id {movie_id}\")\n",
    "        except ValueError:\n",
    "            print(f\"movie_id {movie_id} 在图中找不到对应的索引\")\n",
    "\n",
    "    g.nodes['movieimage'].data['features'] = features_tensor\n",
    "    print(\"特征已成功添加到图中。\")\n",
    "\n",
    "movie_to_youtube = load_youtube_to_movie_mapping('D:\\\\CODE\\\\multi-model knowledge graph multi-graph recommendation system\\\\data\\\\ml-youtube_cleaned.csv')\n",
    "resnet50 = load_pretrained_resnet50()\n",
    "video_folder = 'D:\\\\CODE\\\\multi-model knowledge graph multi-graph recommendation system\\\\data\\\\videos'\n",
    "graphs_to_process = [r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\code\\mainmodel\\hetero_graph03.pkl', r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\code\\mainmodel\\hetero_graph05.pkl', r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\code\\mainmodel\\hetero_graph02.pkl']\n",
    "\n",
    "for graph_path in graphs_to_process:\n",
    "    with open(graph_path, 'rb') as f:\n",
    "        hetero_graph = pickle.load(f)\n",
    "\n",
    "    features_dict = {}\n",
    "    user_movie_edges = hetero_graph.edges(etype=('user', 'rates', 'movie'))\n",
    "    for user_id in torch.unique(user_movie_edges[0]):\n",
    "        movie_ids = user_movie_edges[1][user_movie_edges[0] == user_id]\n",
    "        for movie_id in movie_ids:\n",
    "            actual_movie_id = hetero_graph.nodes['movie'].data['movie_id'][movie_id].item()\n",
    "            youtube_id = movie_to_youtube.get(str(actual_movie_id))\n",
    "            if youtube_id:\n",
    "                video_path = os.path.join(video_folder, f\"{youtube_id}.mp4\")\n",
    "                if os.path.exists(video_path):\n",
    "                    features = extract_features_from_video(video_path, resnet50, preprocess_frames)\n",
    "                    if features is not None:\n",
    "                        features_dict[str(actual_movie_id)] = features\n",
    "\n",
    "    add_features_to_graph(hetero_graph, features_dict)\n",
    "    updated_graph_path = graph_path.replace('.pkl', '_with_features.pkl')\n",
    "    with open(updated_graph_path, 'wb') as f:\n",
    "        pickle.dump(hetero_graph, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 4060 Ti\n",
      "Is model on CUDA: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 检查CUDA设备是否可用\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "# 检查模型是否在CUDA上\n",
    "print(\"Is model on CUDA:\", next(resnet50.parameters()).is_cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies without features: [54995, 57368, 60161, 62956, 64614, 64999, 65514, 66297, 67295, 67799, 67867, 68263, 69526, 70305, 71282, 82095, 61160, 63082, 63992, 68205, 68954, 69122, 69406, 70286, 71535, 72378, 73321, 74789, 76251, 77561, 78209, 79091, 79695, 81562, 81564, 82459, 82461, 84944, 86880, 86911, 87222, 87232, 87430, 88125, 88744, 91500, 91529, 95167, 102125, 102445, 106487, 106489, 106696, 112852, 118696, 125916, 79132, 89085, 92259, 104337, 104841, 104879, 104944, 106766, 106916, 106920, 107069, 107141, 109374, 109673, 110730, 111360, 111622, 111921, 112138, 112290, 112556, 116797, 117511, 117590, 55069, 61236, 61240, 62849, 65596, 66509, 67997, 68194, 69640, 71156, 71379, 71579, 72011, 72733, 73101, 73344, 74787, 77800, 79224, 79463, 80463, 81164, 81817, 81845, 83132, 84116, 84880, 85774, 85881, 86781, 86833, 87192, 87306, 88235, 89118, 89305, 89580, 89753, 89759, 89864, 64839, 66934, 67087, 67255, 68237, 73023, 73323, 74458, 74510, 74545, 78266, 78574, 80549, 80839, 80860, 84392, 84954, 86298, 87869, 88163, 88810, 90719, 91542, 91630, 91658, 93287, 93510, 94070, 94266, 94864, 94896, 95875, 96079, 96610, 96821, 97304, 97324, 97752, 97860, 97913, 97921, 99114, 99728, 100390, 101525, 101864, 102194, 102407, 102903, 103253, 103341, 103384, 103772, 106002, 108188, 108928, 108932, 109864, 110102, 110553, 111362, 111759, 112623, 115617, 62081, 62434, 64969, 65126, 66665, 67734, 68073, 68952, 69757, 70183, 70567, 70687, 71518, 72129, 72407, 75816, 76060, 80094, 80350, 80846, 80862, 81537, 81791, 58107, 59725, 61255, 63479, 67788, 69436, 69644, 59995, 65188, 69574, 69951, 70293, 71033, 71205, 71466, 71619, 72393, 72980, 78039, 86882, 89492, 90405, 91077, 91622, 94959, 96501, 97393, 102588, 103606, 104272, 104374, 84152, 86347, 92535, 113453, 114180]\n"
     ]
    }
   ],
   "source": [
    "def check_missing_features(graph):\n",
    "    missing_features_movies = []\n",
    "    # 假设特征存储在名为 'features' 的节点數據中\n",
    "    for movie_id in graph.nodes['movie'].data['movie_id']:\n",
    "        if 'features' not in graph.nodes['movie'].data or graph.nodes['movie'].data['features'][movie_id].sum() == 0:\n",
    "            missing_features_movies.append(movie_id.item())\n",
    "\n",
    "    if missing_features_movies:\n",
    "        print(\"Movies without features:\", missing_features_movies)\n",
    "    else:\n",
    "        print(\"All movies have features.\")\n",
    "\n",
    "# 假設 hetero_graph 是您已經加載的圖\n",
    "with open('hetero_graph_with_images.pkl', 'rb') as f:\n",
    "    hetero_graph = pickle.load(f)\n",
    "\n",
    "check_missing_features(hetero_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are stored in the graph under 'movieimage' nodes.\n",
      "Shape of features: torch.Size([243, 2048])\n",
      "Sample features: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1471, 0.5938, 0.7490,  ..., 0.1158, 0.3637, 0.1672],\n",
      "        [0.2117, 0.5229, 0.4258,  ..., 0.2200, 0.3178, 0.2677],\n",
      "        [0.4625, 0.3683, 0.3002,  ..., 0.1502, 0.2949, 0.2470],\n",
      "        [0.1799, 0.4742, 0.3313,  ..., 0.1847, 0.3477, 0.1577]])\n"
     ]
    }
   ],
   "source": [
    "# 检查是否存在 'movieimage' 类型的节点以及它们是否有 'features' 属性\n",
    "if 'movieimage' in hetero_graph.ntypes and 'features' in hetero_graph.nodes['movieimage'].data:\n",
    "    features_tensor = hetero_graph.nodes['movieimage'].data['features']\n",
    "    print(\"Features are stored in the graph under 'movieimage' nodes.\")\n",
    "    print(f\"Shape of features: {features_tensor.shape}\")\n",
    "    print(\"Sample features:\", features_tensor[:5])  # 显示前5个特征向量的样例\n",
    "else:\n",
    "    print(\"Features have not been added to the graph.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文字的特徵提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "import speech_recognition as sr\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def enhance_audio(audio_path):\n",
    "    sound = AudioSegment.from_file(audio_path)\n",
    "    # 增加音量\n",
    "    louder = sound + 10  # 增加10dB\n",
    "    enhanced_audio_path = \"enhanced_\" + audio_path\n",
    "    louder.export(enhanced_audio_path, format=\"wav\")\n",
    "    return enhanced_audio_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 加載電影ID到YouTube ID的映射\n",
    "def load_youtube_to_movie_mapping(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    movie_to_youtube = pd.Series(df.youtubeId.values, index=df.movieId.astype(str)).to_dict()\n",
    "    return movie_to_youtube\n",
    "\n",
    "# 提取音頻並轉為文本\n",
    "def extract_audio_to_text(video_path, lang='en-US'):\n",
    "    try:\n",
    "        clip = VideoFileClip(video_path)\n",
    "        audio_path = \"temp_audio.wav\"\n",
    "        clip.audio.write_audiofile(audio_path)\n",
    "        r = sr.Recognizer()\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=lang)\n",
    "        os.remove(audio_path)  # 清理暫存檔案\n",
    "        clip.close()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {video_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 轉換文本為向量\n",
    "def text_to_vector(text):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embedding = model.encode(text)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "\n",
    "def add_text_features_to_graph(g, movie_id, text_features):\n",
    "    # 确保 movietext 节点存在并有正确的特征维度初始化\n",
    "    if 'features' not in g.nodes['movietext'].data:\n",
    "        num_movies = g.number_of_nodes('movietext')\n",
    "        num_features = len(text_features)  # 假设所有特征向量维度相同\n",
    "        g.nodes['movietext'].data['features'] = torch.zeros((num_movies, num_features), dtype=torch.float32)\n",
    "    \n",
    "    # 确定索引并添加特征\n",
    "    idx = g.nodes['movie'].data['movie_id'].tolist().index(int(movie_id))\n",
    "    g.nodes['movietext'].data['features'][idx] = torch.tensor(text_features, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# 載入含影像特徵的圖\n",
    "def load_graph_with_images(graph_path):\n",
    "    with open(graph_path, 'rb') as f:\n",
    "        graph = pickle.load(f)\n",
    "    return graph\n",
    "\n",
    "# def process_videos(graph, mapping_file, video_folder):\n",
    "#     movie_to_youtube = load_youtube_to_movie_mapping(mapping_file)\n",
    "#     movie_ids = graph.nodes['movie'].data['movie_id'].tolist()\n",
    "#     print(f\"Total movies in graph: {len(movie_ids)}\")  # 打印圖中電影總數\n",
    "\n",
    "#     processed_count = 0  # 計數器，追蹤處理了多少視頻\n",
    "\n",
    "#     for movie_id in movie_ids:\n",
    "#         youtube_id = movie_to_youtube.get(str(movie_id))\n",
    "#         if youtube_id:\n",
    "#             video_path = os.path.join(video_folder, f\"{youtube_id}.mp4\")\n",
    "#             if os.path.exists(video_path):\n",
    "#                 print(f\"Processing video for movie ID {movie_id}: {video_path}\")  # 打印正在處理的視頻路徑\n",
    "#                 text = extract_audio_to_text(video_path)\n",
    "#                 if text:\n",
    "#                     print(f\"Extracted text for movie ID {movie_id}: {text[:30]}...\")  # 打印提取的文本概要\n",
    "#                     text_vector = text_to_vector(text)\n",
    "#                     add_text_features_to_graph(graph, movie_id, text_vector)\n",
    "#                     processed_count += 1\n",
    "#                 else:\n",
    "#                     print(f\"No text extracted for movie ID {movie_id}.\")\n",
    "#             else:\n",
    "#                 print(f\"Video file not found: {video_path}\")\n",
    "#         else:\n",
    "#             print(f\"No YouTube ID found for movie ID {movie_id}.\")\n",
    "\n",
    "#     print(f\"Total processed videos: {processed_count}\")  # 打印處理的視頻數量\n",
    "def process_videos(graph, mapping_file, video_folder):\n",
    "    movie_to_youtube = load_youtube_to_movie_mapping(mapping_file)\n",
    "    \n",
    "    # 收集每个用户的前10个互动电影\n",
    "    user_movie_edges = graph.edges(etype=('user', 'rates', 'movie'))\n",
    "    top_movies_per_user = {}\n",
    "    for user_id, movie_id in zip(user_movie_edges[0].numpy(), user_movie_edges[1].numpy()):\n",
    "        if user_id not in top_movies_per_user:\n",
    "            top_movies_per_user[user_id] = []\n",
    "        if len(top_movies_per_user[user_id]) < 10:\n",
    "            top_movies_per_user[user_id].append(movie_id)\n",
    "\n",
    "    # 将列表扁平化，获取所有需要处理的电影ID\n",
    "    top_movie_ids = set([movie_id for movie_list in top_movies_per_user.values() for movie_id in movie_list])\n",
    "\n",
    "    processed_count = 0\n",
    "    for movie_id in top_movie_ids:\n",
    "        actual_movie_id = graph.nodes['movie'].data['movie_id'][movie_id].item()  # 获取实际的movie_id\n",
    "        youtube_id = movie_to_youtube.get(str(actual_movie_id))\n",
    "        if youtube_id:\n",
    "            video_path = os.path.join(video_folder, f\"{youtube_id}.mp4\")\n",
    "            if os.path.exists(video_path):\n",
    "                print(f\"Processing video for movie ID {actual_movie_id}: {video_path}\")\n",
    "                text = extract_audio_to_text(video_path)\n",
    "                if text:\n",
    "                    text_vector = text_to_vector(text)\n",
    "                    add_text_features_to_graph(graph, actual_movie_id, text_vector)\n",
    "                    processed_count += 1\n",
    "                else:\n",
    "                    print(f\"No text extracted for movie ID {actual_movie_id}.\")\n",
    "            else:\n",
    "                print(f\"Video file not found: {video_path}\")\n",
    "        else:\n",
    "            print(f\"No YouTube ID found for movie ID {actual_movie_id}.\")\n",
    "\n",
    "    print(f\"Total processed videos: {processed_count}\")\n",
    "\n",
    "# 繼續使用前面的設置和調用程式碼\n",
    "\n",
    "\n",
    "# 讀取圖並處理文本\n",
    "graph_path = 'hetero_graph_with_images.pkl'\n",
    "video_folder = r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\data\\videos'\n",
    "mapping_file = r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\data\\ml-youtube_cleaned.csv'\n",
    "hetero_graph = load_graph_with_images(graph_path)\n",
    "\n",
    "process_videos(hetero_graph, mapping_file, video_folder)\n",
    "\n",
    "# 保存更新后的圖像和文本特徵圖\n",
    "with open('hetero_graph_with_images_text.pkl', 'wb') as f:\n",
    "    pickle.dump(hetero_graph, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-MP4 files found:\n",
      "EAPy76vxF5s.f251.webm.part\n",
      "N07qVsND8p4.f244.webm.part\n",
      "pTbIu8Zeqp0.f251.webm.part\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def check_non_mp4_files(directory):\n",
    "    non_mp4_files = [file for file in os.listdir(directory) if not file.endswith('.mp4')]\n",
    "    return non_mp4_files\n",
    "\n",
    "# 指定要檢查的文件夾路徑\n",
    "video_folder = r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\data\\videos'\n",
    "non_mp4_files = check_non_mp4_files(video_folder)\n",
    "\n",
    "if non_mp4_files:\n",
    "    print(\"Non-MP4 files found:\")\n",
    "    for file in non_mp4_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"No non-MP4 files found in the directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are available in 'movietext' nodes.\n",
      "Shape of the features: torch.Size([243, 384])\n",
      "Features have the correct dimension.\n",
      "Average of features: 2.932727693405468e-05\n",
      "Non-zero elements in features: 18816\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设 hetero_graph 是你的图变量\n",
    "if 'movietext' in hetero_graph.ntypes:\n",
    "    if 'features' in hetero_graph.nodes['movietext'].data:\n",
    "        features = hetero_graph.nodes['movietext'].data['features']\n",
    "        print(\"Features are available in 'movietext' nodes.\")\n",
    "        print(f\"Shape of the features: {features.shape}\")\n",
    "    else:\n",
    "        print(\"No features data found in 'movietext' nodes.\")\n",
    "else:\n",
    "    print(\"No 'movietext' node type found in the graph.\")\n",
    "if 'features' in hetero_graph.nodes['movietext'].data:\n",
    "    features = hetero_graph.nodes['movietext'].data['features']\n",
    "    if features.shape[1] == 384:  # 假设每个特征向量长度为384\n",
    "        print(\"Features have the correct dimension.\")\n",
    "    else:\n",
    "        print(f\"Incorrect dimension of features: {features.shape[1]}\")\n",
    "if 'features' in hetero_graph.nodes['movietext'].data:\n",
    "    features = hetero_graph.nodes['movietext'].data['features']\n",
    "    print(f\"Average of features: {torch.mean(features)}\")\n",
    "    print(f\"Non-zero elements in features: {torch.count_nonzero(features)}\")\n",
    "# 保存图\n",
    "with open('hetero_graph_with_images_text.pkl', 'wb') as f:\n",
    "    pickle.dump(hetero_graph, f)\n",
    "\n",
    "# 加载图\n",
    "with open('hetero_graph_with_images_text.pkl', 'rb') as f:\n",
    "    loaded_graph = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 聲音的特徵提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 检查音频特征是否正确加入图中\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\TFTORGPR\\lib\\site-packages\\torch\\__init__.py:125\u001b[0m\n\u001b[0;32m    123\u001b[0m is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_load_library_flags:\n\u001b[1;32m--> 125\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mkernel32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadLibraryExW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0x00001100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     last_error \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mget_last_error()\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m last_error \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m126\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# 检查音频特征是否正确加入图中\n",
    "def check_audio_features(graph):\n",
    "    if 'movieaudio' in graph.ntypes:\n",
    "        if 'features' in graph.nodes['movieaudio'].data:\n",
    "            features = graph.nodes['movieaudio'].data['features']\n",
    "            print(\"Audio features are available in 'movieaudio' nodes.\")\n",
    "            print(f\"Shape of the features: {features.shape}\")\n",
    "            # 假设你知道音频特征向量的预期长度\n",
    "            expected_feature_length = 128  # 假设音频特征长度为128\n",
    "            if features.shape[1] == expected_feature_length:\n",
    "                print(\"Features have the correct dimension.\")\n",
    "            else:\n",
    "                print(f\"Incorrect dimension of features: {features.shape[1]}\")\n",
    "            print(f\"Average of features: {torch.mean(features)}\")\n",
    "            print(f\"Non-zero elements in features: {torch.count_nonzero(features)}\")\n",
    "        else:\n",
    "            print(\"No features data found in 'movieaudio' nodes.\")\n",
    "    else:\n",
    "        print(\"No 'movieaudio' node type found in the graph.\")\n",
    "\n",
    "# 保存图\n",
    "def save_graph(graph, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(graph, f)\n",
    "    print(f\"Graph saved to {filename}\")\n",
    "\n",
    "# 加载图\n",
    "def load_graph(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# 使用以上定义的函数\n",
    "filename = 'hetero_graph_with_images_text_audio.pkl'\n",
    "save_graph(hetero_graph, filename)\n",
    "loaded_graph = load_graph(filename)\n",
    "check_audio_features(loaded_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "if hetero_graph is not None:\n",
    "    save_graph(hetero_graph, filename)\n",
    "    print(\"图已被确认非空并尝试保存。\")\n",
    "else:\n",
    "    print(\"图是空的，保存操作被跳过。\")\n",
    "# 保存图\n",
    "save_graph(hetero_graph, filename)\n",
    "\n",
    "# 立即尝试加载图\n",
    "loaded_graph = load_graph(filename)\n",
    "\n",
    "if loaded_graph is not None:\n",
    "    print(\"图成功加载。\")\n",
    "    check_audio_features(loaded_graph)\n",
    "else:\n",
    "    print(\"加载图失败，对象为空。\")\n",
    "import pickle\n",
    "\n",
    "def save_graph(graph, filename):\n",
    "    try:\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(graph, f)\n",
    "        print(f\"图已保存到 {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存图时发生错误: {e}\")\n",
    "\n",
    "def load_graph(filename):\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"加载图时发生错误: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspeech_recognition\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msr\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\GNN\\lib\\site-packages\\torch\\__init__.py:465\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;124m                or by running Python from a different directory.\u001b[39m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'''\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m):\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    467\u001b[0m         __all__\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from moviepy.editor import VideoFileClip\n",
    "import speech_recognition as sr\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def load_youtube_to_movie_mapping(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    movie_to_youtube = pd.Series(df.youtubeId.values, index=df.movieId.astype(str)).to_dict()\n",
    "    return movie_to_youtube\n",
    "\n",
    "def extract_audio_to_text(video_path, lang='en-US', start_sec=10, end_sec=60):\n",
    "    try:\n",
    "        clip = VideoFileClip(video_path).subclip(start_sec, end_sec)\n",
    "        audio_path = \"temp_audio.wav\"\n",
    "        clip.audio.write_audiofile(audio_path)\n",
    "        r = sr.Recognizer()\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=lang)\n",
    "        os.remove(audio_path)\n",
    "        clip.close()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {video_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def text_to_vector_or_zero(text, vector_length=384):\n",
    "    if text:\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        return model.encode(text)\n",
    "    else:\n",
    "        return torch.zeros(vector_length)\n",
    "\n",
    "def add_text_features_to_graph(g, movie_id, text_features):\n",
    "    if 'features' not in g.nodes['movietext'].data:\n",
    "        num_movies = g.number_of_nodes('movietext')\n",
    "        num_features = text_features.shape[0] if text_features is not None else 384\n",
    "        g.nodes['movietext'].data['features'] = torch.zeros((num_movies, num_features), dtype=torch.float32)\n",
    "    idx = g.nodes['movie'].data['movie_id'].tolist().index(int(movie_id))\n",
    "    g.nodes['movietext'].data['features'][idx] = torch.tensor(text_features, dtype=torch.float32)\n",
    "\n",
    "def process_videos(graph, mapping_file, video_folder, output_file):\n",
    "    movie_to_youtube = load_youtube_to_movie_mapping(mapping_file)\n",
    "    all_movie_ids = set([mid.item() for mid in graph.nodes['movie'].data['movie_id']])\n",
    "    processed_count = 0\n",
    "    problematic_movies = []\n",
    "\n",
    "    for movie_id in all_movie_ids:\n",
    "        youtube_id = movie_to_youtube.get(str(movie_id))\n",
    "        if youtube_id:\n",
    "            video_path = os.path.join(video_folder, f\"{youtube_id}.mp4\")\n",
    "            if os.path.exists(video_path):\n",
    "                text = extract_audio_to_text(video_path)\n",
    "                text_vector = text_to_vector_or_zero(text)\n",
    "                add_text_features_to_graph(graph, movie_id, text_vector)\n",
    "                processed_count += 1\n",
    "                if text is None:\n",
    "                    problematic_movies.append(movie_id)\n",
    "                    print(f\"No text extracted for movie ID {movie_id}.\")\n",
    "            else:\n",
    "                problematic_movies.append(movie_id)\n",
    "                print(f\"Video file not found: {video_path}\")\n",
    "        else:\n",
    "            problematic_movies.append(movie_id)\n",
    "            print(f\"No YouTube ID found for movie ID {movie_id}.\")\n",
    "\n",
    "    print(f\"Total processed videos: {processed_count}\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        for movie_id in problematic_movies:\n",
    "            f.write(f\"{movie_id}\\n\")\n",
    "\n",
    "# File paths\n",
    "video_folder = r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\data\\videos'\n",
    "mapping_file = r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\data\\ml-youtube_cleaned.csv'\n",
    "\n",
    "# Process each graph\n",
    "graphs_to_process = [\n",
    "    r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\code\\mainmodel\\hetero_graph03.pkl',\n",
    "    r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\code\\mainmodel\\hetero_graph05.pkl',\n",
    "    r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\code\\mainmodel\\hetero_graph08.pkl',\n",
    "    r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\code\\mainmodel\\hetero_graph03_with_features.pkl',\n",
    "    r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\code\\mainmodel\\hetero_graph05_with_features.pkl',\n",
    "    r'D:\\CODE\\multi-model knowledge graph multi-graph recommendation system\\code\\mainmodel\\hetero_graph08_with_features.pkl'\n",
    "]\n",
    "\n",
    "for graph_path in graphs_to_process:\n",
    "    graph = pickle.load(open(graph_path, 'rb'))\n",
    "    output_file = graph_path.replace('.pkl', '_problematic_movies.txt')\n",
    "    process_videos(graph, mapping_file, video_folder, output_file)\n",
    "    updated_graph_path = graph_path.replace('.pkl', '_with_text_features.pkl')\n",
    "    with open(updated_graph_path, 'wb') as f:\n",
    "        pickle.dump(graph, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFTORGPR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
